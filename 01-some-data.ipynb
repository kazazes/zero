{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First instinct to make money with LLMs is: scrape headlines from a few sources, FT, drudge, bloomberg, scan for company names, get their performance in that day, fine tune _a model to predict the performance of a company based on the news, and then trade on that._\n",
    "\n",
    "Or we could do macro-vibe trading, take the above the fold headlines, line them up with S&P opens and closes, finetune, predict. \n",
    "\n",
    "Okay, so we need a website snapshotter that'll get past bot detections. But we also need training data, so we'll use the wayback machine. Time for some python.\n",
    "\n",
    "Let's get the sources then see what we can cook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: waybackpy in ./.venv/lib/python3.11/site-packages (3.0.6)\n",
      "Requirement already satisfied: beautifulsoup4 in ./.venv/lib/python3.11/site-packages (4.12.3)\n",
      "Requirement already satisfied: click in ./.venv/lib/python3.11/site-packages (from waybackpy) (8.1.7)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.11/site-packages (from waybackpy) (2.31.0)\n",
      "Requirement already satisfied: urllib3 in ./.venv/lib/python3.11/site-packages (from waybackpy) (2.2.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./.venv/lib/python3.11/site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests->waybackpy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests->waybackpy) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests->waybackpy) (2024.2.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install waybackpy beautifulsoup4 retrying python-dotenv tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use waybackpy to get the last year of drudge, every day at 9 AM ET.\n",
    "# from waybackpy import WaybackMachineCDXServerAPI\n",
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "\n",
    "# url = \"https://drudgereport.com/\"\n",
    "\n",
    "# # pass url, a year, month, day, hour, and minute, returning a list of tuples of url and text\n",
    "# def get_page_links_at_date(url, year, month, day, hour, minute):\n",
    "#     w = WaybackMachineCDXServerAPI(url, user_agent=user_agent)\n",
    "#     url = w.near(year=year, month=month, day=day, hour=hour, minute=minute).archive_url\n",
    "#     response = requests.get(url)\n",
    "#     soup = BeautifulSoup(response.text, 'html.parser')\n",
    "#     links = soup.find_all('a')\n",
    "#     article_links = [(link.get('href'), link.text) for link in links]\n",
    "#     article_links = [link for link in article_links if link[1]]\n",
    "#     return article_links\n",
    "\n",
    "# links = get_page_links_at_date(\"https://drudgereport.com/\", year=2023, month=2, day=27, hour=9, minute=0)\n",
    "\n",
    "# for url, text in links[:5]:\n",
    "#     print(f\"Text: {text} URL: {url}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thank you _for your help_ GPT. _I'm going to use the wayback machine to get the last year of drudge, every day at 9 AM ET, and 5._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# now = pd.Timestamp.now()\n",
    "# dates = pd.date_range(start=\"2022-02-01\", end=now, freq=\"D\")\n",
    "\n",
    "# data = []\n",
    "\n",
    "# for date in dates:\n",
    "#     am_links = get_page_links_at_date(\"https://drudgereport.com/\", year=date.year, month=date.month, day=date.day, hour=6, minute=0)\n",
    "#     for url, text in am_links:\n",
    "#         data.append({\"date\": date.isoformat(), \"url\": url, \"text\": text, isMorning: True}, ignore_index=True)\n",
    "#     pm_links = get_page_links_at_date(\"https://drudgereport.com/\", year=date.year, month=date.month, day=date.day, hour=18, minute=0)\n",
    "#     for url, text in pm_links:\n",
    "#         data.append({\"date\": date.isoformat(), \"url\": url, \"text\": text, isMorning: False}, ignore_index=True)\n",
    "\n",
    "# drudge_df = pd.DataFrame(data)\n",
    "# drudge_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh no they blocked me. Love you archive.org, didn't mean to upset you. Let's use a proxy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from waybackpy import WaybackMachineCDXServerAPI\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "username = os.getenv('SMARTPROXY_USERNAME')\n",
    "password = os.getenv('SMARTPROXY_PASSWORD')\n",
    "proxy = f\"https://{username}:{password}@gate.smartproxy.com:7000\"\n",
    "\n",
    "proxies = {'https': proxy}\n",
    "user_agent = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36\"\n",
    "headers = {'User-Agent': user_agent}\n",
    "\n",
    "def play_success_sound():\n",
    "    os.system('afplay /System/Library/Sounds/Pop.aiff')\n",
    "\n",
    "def get_drudge_links_at_date(url, year, month, day, hour, minute):\n",
    "    w = WaybackMachineCDXServerAPI(url, user_agent=user_agent)\n",
    "    url = w.near(year=year, month=month, day=day, hour=hour, minute=minute).archive_url\n",
    "    response = requests.get(url, headers=headers, proxies=proxies)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    links = soup.find_all('a')\n",
    "    article_links = [(link.get('href'), link.text) for link in links]\n",
    "    article_links = [link for link in article_links if link[1]]\n",
    "    return article_links\n",
    "\n",
    "def scrape_drudge_with_proxy():\n",
    "    now = pd.Timestamp.now()\n",
    "    dates = pd.date_range(start=\"2022-01-01\", end=now, freq=\"D\")\n",
    "\n",
    "    for date in tqdm(dates, desc=\"Drudge progress\", unit=\"date\"):\n",
    "        # check if we already have the data\n",
    "        if os.path.exists(f\"01-some-data/drudgereport.com/{date}.jsonl\"):\n",
    "            continue\n",
    "        data = []\n",
    "        am_links = get_drudge_links_at_date(\"https://drudgereport.com/\", year=date.year, month=date.month, day=date.day, hour=6, minute=0)\n",
    "        for url, text in am_links:\n",
    "            data.append({\"date\": date.isoformat(), \"url\": url, \"text\": text, \"isMorning\": True})\n",
    "        pm_links = get_drudge_links_at_date(\"https://drudgereport.com/\", year=date.year, month=date.month, day=date.day, hour=18, minute=0)\n",
    "        for url, text in pm_links:\n",
    "            data.append({\"date\": date.isoformat(), \"url\": url, \"text\": text, \"isMorning\": False})\n",
    "        # write to jsonl\n",
    "        with open(f\"01-some-data/drudgereport.com/{date}.jsonl\", \"w\") as f:\n",
    "            for row in data:\n",
    "                f.write(json.dumps(row) + \"\\n\")\n",
    "        play_success_sound()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping is a muddy art, let's let this baby run with some backoff retry logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from retrying import retry\n",
    "\n",
    "@retry(wait_exponential_multiplier=1000, wait_exponential_max=60000)\n",
    "def scrape_drudge_with_proxy_retry():\n",
    "    scrape_drudge_with_proxy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lovely. But there are a lot of non-news item links in the scrapes. Let's only include urls with more than one path component and clean up the archive.org prefaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "def clean_up_drudge_links():\n",
    "    # iterate over each file in the directory\n",
    "    preprune_count = 0\n",
    "    postprune_count = 0\n",
    "    for filename in os.listdir(\"01-some-data/drudgereport.com\"):\n",
    "        filepath = os.path.join(\"01-some-data/drudgereport.com\", filename)\n",
    "        with open(filepath, 'r') as f:\n",
    "            data = [json.loads(line) for line in f]\n",
    "\n",
    "        # regex pattern to match 'https://web.archive.org/web/{date as integer}'\n",
    "        pattern = r\"https://web\\.archive\\.org/web/\\d+/\"\n",
    "\n",
    "        # iterate over each item in the data\n",
    "        for item in data:\n",
    "            # replace the matched pattern with an empty string\n",
    "            item['url'] = re.sub(pattern, '', item['url'])\n",
    "        # filter out urls with only one path component\n",
    "        filtered = [item for item in data if len(urlparse(item['url']).path.split('/')) > 2]\n",
    "        # remove internal links to drudge\n",
    "        filtered = [item for item in filtered if \"drudgereport.com\" not in item['url']]\n",
    "        # remove items with less than three words in text\n",
    "        # filtered = [item for item in filtered if len(item['text'].split()) > 2]\n",
    "\n",
    "        preprune_count += len(data)\n",
    "        postprune_count += len(filtered)\n",
    "\n",
    "        # write the filtered data back to the file\n",
    "        with open(filepath, 'w') as f:\n",
    "            for item in filtered:\n",
    "                f.write(json.dumps(item) + \"\\n\")\n",
    "\n",
    "        print(f\"Preprune count: {preprune_count}\")\n",
    "        print(f\"Postprune count: {postprune_count}\")\n",
    "        print(f\"Pruned {preprune_count - postprune_count} links or {((preprune_count - postprune_count) / preprune_count) * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprune count: 230\n",
      "Postprune count: 230\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 485\n",
      "Postprune count: 485\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 746\n",
      "Postprune count: 746\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 964\n",
      "Postprune count: 964\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 1208\n",
      "Postprune count: 1208\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 1457\n",
      "Postprune count: 1457\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 1688\n",
      "Postprune count: 1688\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 1945\n",
      "Postprune count: 1945\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 2158\n",
      "Postprune count: 2158\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 2429\n",
      "Postprune count: 2429\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 2670\n",
      "Postprune count: 2670\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 2938\n",
      "Postprune count: 2938\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 3211\n",
      "Postprune count: 3211\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 3469\n",
      "Postprune count: 3469\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 3731\n",
      "Postprune count: 3731\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 4002\n",
      "Postprune count: 4002\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 4276\n",
      "Postprune count: 4276\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 4492\n",
      "Postprune count: 4492\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 4749\n",
      "Postprune count: 4749\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 5018\n",
      "Postprune count: 5018\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 5255\n",
      "Postprune count: 5255\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 5513\n",
      "Postprune count: 5513\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 5729\n",
      "Postprune count: 5729\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 5987\n",
      "Postprune count: 5987\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 6234\n",
      "Postprune count: 6234\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 6445\n",
      "Postprune count: 6445\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 6699\n",
      "Postprune count: 6699\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 6947\n",
      "Postprune count: 6947\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 7155\n",
      "Postprune count: 7155\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 7411\n",
      "Postprune count: 7411\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 7664\n",
      "Postprune count: 7664\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 7941\n",
      "Postprune count: 7941\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 8205\n",
      "Postprune count: 8205\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 8473\n",
      "Postprune count: 8473\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 8732\n",
      "Postprune count: 8732\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 8997\n",
      "Postprune count: 8997\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 9217\n",
      "Postprune count: 9217\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 9449\n",
      "Postprune count: 9449\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 9701\n",
      "Postprune count: 9701\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 9953\n",
      "Postprune count: 9953\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 10219\n",
      "Postprune count: 10219\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 10470\n",
      "Postprune count: 10470\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 10690\n",
      "Postprune count: 10690\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 10936\n",
      "Postprune count: 10936\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 11217\n",
      "Postprune count: 11217\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 11467\n",
      "Postprune count: 11467\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 11719\n",
      "Postprune count: 11719\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 11975\n",
      "Postprune count: 11975\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 12223\n",
      "Postprune count: 12223\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 12481\n",
      "Postprune count: 12481\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 12700\n",
      "Postprune count: 12700\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 12963\n",
      "Postprune count: 12963\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 13229\n",
      "Postprune count: 13229\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 13454\n",
      "Postprune count: 13454\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 13692\n",
      "Postprune count: 13692\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 13938\n",
      "Postprune count: 13938\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 14196\n",
      "Postprune count: 14196\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 14465\n",
      "Postprune count: 14465\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 14716\n",
      "Postprune count: 14716\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 14934\n",
      "Postprune count: 14934\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 15168\n",
      "Postprune count: 15168\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 15401\n",
      "Postprune count: 15401\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 15675\n",
      "Postprune count: 15675\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 15935\n",
      "Postprune count: 15935\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 16190\n",
      "Postprune count: 16190\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 16473\n",
      "Postprune count: 16473\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 16709\n",
      "Postprune count: 16709\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 16959\n",
      "Postprune count: 16959\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 17219\n",
      "Postprune count: 17219\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 17437\n",
      "Postprune count: 17437\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 17717\n",
      "Postprune count: 17717\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 17974\n",
      "Postprune count: 17974\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 18212\n",
      "Postprune count: 18212\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 18433\n",
      "Postprune count: 18433\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 18706\n",
      "Postprune count: 18706\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 18968\n",
      "Postprune count: 18968\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 19189\n",
      "Postprune count: 19189\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 19434\n",
      "Postprune count: 19434\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 19702\n",
      "Postprune count: 19702\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 19918\n",
      "Postprune count: 19918\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 20187\n",
      "Postprune count: 20187\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 20433\n",
      "Postprune count: 20433\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 20680\n",
      "Postprune count: 20680\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 20895\n",
      "Postprune count: 20895\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 21132\n",
      "Postprune count: 21132\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 21381\n",
      "Postprune count: 21381\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 21627\n",
      "Postprune count: 21627\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 21861\n",
      "Postprune count: 21861\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 22122\n",
      "Postprune count: 22122\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 22382\n",
      "Postprune count: 22382\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 22639\n",
      "Postprune count: 22639\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 22639\n",
      "Postprune count: 22639\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 22886\n",
      "Postprune count: 22886\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 23132\n",
      "Postprune count: 23132\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 23345\n",
      "Postprune count: 23345\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 23551\n",
      "Postprune count: 23551\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 23839\n",
      "Postprune count: 23839\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 24109\n",
      "Postprune count: 24109\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 24376\n",
      "Postprune count: 24376\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 24643\n",
      "Postprune count: 24643\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 24902\n",
      "Postprune count: 24902\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 25109\n",
      "Postprune count: 25109\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 25319\n",
      "Postprune count: 25319\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 25577\n",
      "Postprune count: 25577\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 25823\n",
      "Postprune count: 25823\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 26096\n",
      "Postprune count: 26096\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 26361\n",
      "Postprune count: 26361\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 26603\n",
      "Postprune count: 26603\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 26852\n",
      "Postprune count: 26852\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 27134\n",
      "Postprune count: 27134\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 27394\n",
      "Postprune count: 27394\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 27652\n",
      "Postprune count: 27652\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 27930\n",
      "Postprune count: 27930\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 28182\n",
      "Postprune count: 28182\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 28398\n",
      "Postprune count: 28398\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 28664\n",
      "Postprune count: 28664\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 28916\n",
      "Postprune count: 28916\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 29195\n",
      "Postprune count: 29195\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 29440\n",
      "Postprune count: 29440\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 29709\n",
      "Postprune count: 29709\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 29922\n",
      "Postprune count: 29922\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 30125\n",
      "Postprune count: 30125\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 30346\n",
      "Postprune count: 30346\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 30577\n",
      "Postprune count: 30577\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 30852\n",
      "Postprune count: 30852\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 31097\n",
      "Postprune count: 31097\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 31358\n",
      "Postprune count: 31358\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 31589\n",
      "Postprune count: 31589\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 31820\n",
      "Postprune count: 31820\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 32060\n",
      "Postprune count: 32060\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 32307\n",
      "Postprune count: 32307\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 32565\n",
      "Postprune count: 32565\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 32812\n",
      "Postprune count: 32812\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 33030\n",
      "Postprune count: 33030\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 33243\n",
      "Postprune count: 33243\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 33455\n",
      "Postprune count: 33455\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 33735\n",
      "Postprune count: 33735\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 33982\n",
      "Postprune count: 33982\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 34258\n",
      "Postprune count: 34258\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 34507\n",
      "Postprune count: 34507\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 34774\n",
      "Postprune count: 34774\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 35033\n",
      "Postprune count: 35033\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 35284\n",
      "Postprune count: 35284\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 35524\n",
      "Postprune count: 35524\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 35785\n",
      "Postprune count: 35785\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 36052\n",
      "Postprune count: 36052\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 36314\n",
      "Postprune count: 36314\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 36531\n",
      "Postprune count: 36531\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 36762\n",
      "Postprune count: 36762\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 36992\n",
      "Postprune count: 36992\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 37230\n",
      "Postprune count: 37230\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 37230\n",
      "Postprune count: 37230\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 37491\n",
      "Postprune count: 37491\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 37763\n",
      "Postprune count: 37763\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 37972\n",
      "Postprune count: 37972\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 38192\n",
      "Postprune count: 38192\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 38450\n",
      "Postprune count: 38450\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 38706\n",
      "Postprune count: 38706\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 38980\n",
      "Postprune count: 38980\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 39232\n",
      "Postprune count: 39232\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 39476\n",
      "Postprune count: 39476\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 39738\n",
      "Postprune count: 39738\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 40014\n",
      "Postprune count: 40014\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 40280\n",
      "Postprune count: 40280\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 40523\n",
      "Postprune count: 40523\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 40759\n",
      "Postprune count: 40759\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 41016\n",
      "Postprune count: 41016\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 41229\n",
      "Postprune count: 41229\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 41452\n",
      "Postprune count: 41452\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 41700\n",
      "Postprune count: 41700\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 41953\n",
      "Postprune count: 41953\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 42222\n",
      "Postprune count: 42222\n",
      "Pruned 0 links or 0.00%\n",
      "Preprune count: 42705\n",
      "Postprune count: 42476\n",
      "Pruned 229 links or 0.54%\n",
      "Preprune count: 42967\n",
      "Postprune count: 42738\n",
      "Pruned 229 links or 0.53%\n",
      "Preprune count: 43214\n",
      "Postprune count: 42985\n",
      "Pruned 229 links or 0.53%\n",
      "Preprune count: 43422\n",
      "Postprune count: 43193\n",
      "Pruned 229 links or 0.53%\n",
      "Preprune count: 43644\n",
      "Postprune count: 43415\n",
      "Pruned 229 links or 0.52%\n",
      "Preprune count: 43858\n",
      "Postprune count: 43629\n",
      "Pruned 229 links or 0.52%\n",
      "Preprune count: 44079\n",
      "Postprune count: 43850\n",
      "Pruned 229 links or 0.52%\n",
      "Preprune count: 44352\n",
      "Postprune count: 44123\n",
      "Pruned 229 links or 0.52%\n",
      "Preprune count: 44603\n",
      "Postprune count: 44374\n",
      "Pruned 229 links or 0.51%\n",
      "Preprune count: 44815\n",
      "Postprune count: 44586\n",
      "Pruned 229 links or 0.51%\n",
      "Preprune count: 45069\n",
      "Postprune count: 44840\n",
      "Pruned 229 links or 0.51%\n",
      "Preprune count: 45331\n",
      "Postprune count: 45102\n",
      "Pruned 229 links or 0.51%\n",
      "Preprune count: 45583\n",
      "Postprune count: 45354\n",
      "Pruned 229 links or 0.50%\n",
      "Preprune count: 45827\n",
      "Postprune count: 45598\n",
      "Pruned 229 links or 0.50%\n",
      "Preprune count: 46043\n",
      "Postprune count: 45814\n",
      "Pruned 229 links or 0.50%\n",
      "Preprune count: 46272\n",
      "Postprune count: 46043\n",
      "Pruned 229 links or 0.49%\n",
      "Preprune count: 46543\n",
      "Postprune count: 46314\n",
      "Pruned 229 links or 0.49%\n",
      "Preprune count: 46762\n",
      "Postprune count: 46533\n",
      "Pruned 229 links or 0.49%\n",
      "Preprune count: 46992\n",
      "Postprune count: 46763\n",
      "Pruned 229 links or 0.49%\n",
      "Preprune count: 47226\n",
      "Postprune count: 46997\n",
      "Pruned 229 links or 0.48%\n",
      "Preprune count: 47450\n",
      "Postprune count: 47221\n",
      "Pruned 229 links or 0.48%\n",
      "Preprune count: 47688\n",
      "Postprune count: 47459\n",
      "Pruned 229 links or 0.48%\n",
      "Preprune count: 47932\n",
      "Postprune count: 47703\n",
      "Pruned 229 links or 0.48%\n",
      "Preprune count: 48185\n",
      "Postprune count: 47956\n",
      "Pruned 229 links or 0.48%\n",
      "Preprune count: 48430\n",
      "Postprune count: 48201\n",
      "Pruned 229 links or 0.47%\n",
      "Preprune count: 48696\n",
      "Postprune count: 48467\n",
      "Pruned 229 links or 0.47%\n",
      "Preprune count: 48910\n",
      "Postprune count: 48681\n",
      "Pruned 229 links or 0.47%\n",
      "Preprune count: 49145\n",
      "Postprune count: 48916\n",
      "Pruned 229 links or 0.47%\n",
      "Preprune count: 49418\n",
      "Postprune count: 49189\n",
      "Pruned 229 links or 0.46%\n",
      "Preprune count: 49630\n",
      "Postprune count: 49401\n",
      "Pruned 229 links or 0.46%\n",
      "Preprune count: 49908\n",
      "Postprune count: 49679\n",
      "Pruned 229 links or 0.46%\n",
      "Preprune count: 50147\n",
      "Postprune count: 49918\n",
      "Pruned 229 links or 0.46%\n",
      "Preprune count: 50390\n",
      "Postprune count: 50161\n",
      "Pruned 229 links or 0.45%\n",
      "Preprune count: 50624\n",
      "Postprune count: 50395\n",
      "Pruned 229 links or 0.45%\n",
      "Preprune count: 50881\n",
      "Postprune count: 50652\n",
      "Pruned 229 links or 0.45%\n",
      "Preprune count: 51092\n",
      "Postprune count: 50863\n",
      "Pruned 229 links or 0.45%\n",
      "Preprune count: 51304\n",
      "Postprune count: 51075\n",
      "Pruned 229 links or 0.45%\n",
      "Preprune count: 51570\n",
      "Postprune count: 51341\n",
      "Pruned 229 links or 0.44%\n",
      "Preprune count: 51807\n",
      "Postprune count: 51578\n",
      "Pruned 229 links or 0.44%\n",
      "Preprune count: 52070\n",
      "Postprune count: 51841\n",
      "Pruned 229 links or 0.44%\n",
      "Preprune count: 52557\n",
      "Postprune count: 52099\n",
      "Pruned 458 links or 0.87%\n",
      "Preprune count: 52820\n",
      "Postprune count: 52362\n",
      "Pruned 458 links or 0.87%\n",
      "Preprune count: 53066\n",
      "Postprune count: 52608\n",
      "Pruned 458 links or 0.86%\n",
      "Preprune count: 53298\n",
      "Postprune count: 52840\n",
      "Pruned 458 links or 0.86%\n",
      "Preprune count: 53514\n",
      "Postprune count: 53056\n",
      "Pruned 458 links or 0.86%\n",
      "Preprune count: 53732\n",
      "Postprune count: 53274\n",
      "Pruned 458 links or 0.85%\n",
      "Preprune count: 53946\n",
      "Postprune count: 53488\n",
      "Pruned 458 links or 0.85%\n",
      "Preprune count: 54199\n",
      "Postprune count: 53741\n",
      "Pruned 458 links or 0.85%\n",
      "Preprune count: 54448\n",
      "Postprune count: 53990\n",
      "Pruned 458 links or 0.84%\n",
      "Preprune count: 54682\n",
      "Postprune count: 54224\n",
      "Pruned 458 links or 0.84%\n",
      "Preprune count: 54924\n",
      "Postprune count: 54466\n",
      "Pruned 458 links or 0.83%\n",
      "Preprune count: 55170\n",
      "Postprune count: 54712\n",
      "Pruned 458 links or 0.83%\n",
      "Preprune count: 55417\n",
      "Postprune count: 54959\n",
      "Pruned 458 links or 0.83%\n",
      "Preprune count: 55630\n",
      "Postprune count: 55172\n",
      "Pruned 458 links or 0.82%\n",
      "Preprune count: 55899\n",
      "Postprune count: 55441\n",
      "Pruned 458 links or 0.82%\n",
      "Preprune count: 56142\n",
      "Postprune count: 55684\n",
      "Pruned 458 links or 0.82%\n",
      "Preprune count: 56365\n",
      "Postprune count: 55907\n",
      "Pruned 458 links or 0.81%\n",
      "Preprune count: 56580\n",
      "Postprune count: 56122\n",
      "Pruned 458 links or 0.81%\n",
      "Preprune count: 56799\n",
      "Postprune count: 56341\n",
      "Pruned 458 links or 0.81%\n",
      "Preprune count: 57069\n",
      "Postprune count: 56611\n",
      "Pruned 458 links or 0.80%\n",
      "Preprune count: 57273\n",
      "Postprune count: 56815\n",
      "Pruned 458 links or 0.80%\n",
      "Preprune count: 57490\n",
      "Postprune count: 57032\n",
      "Pruned 458 links or 0.80%\n",
      "Preprune count: 57711\n",
      "Postprune count: 57253\n",
      "Pruned 458 links or 0.79%\n",
      "Preprune count: 57932\n",
      "Postprune count: 57474\n",
      "Pruned 458 links or 0.79%\n",
      "Preprune count: 58186\n",
      "Postprune count: 57728\n",
      "Pruned 458 links or 0.79%\n",
      "Preprune count: 58443\n",
      "Postprune count: 57985\n",
      "Pruned 458 links or 0.78%\n",
      "Preprune count: 58918\n",
      "Postprune count: 58232\n",
      "Pruned 686 links or 1.16%\n",
      "Preprune count: 59173\n",
      "Postprune count: 58487\n",
      "Pruned 686 links or 1.16%\n",
      "Preprune count: 59424\n",
      "Postprune count: 58738\n",
      "Pruned 686 links or 1.15%\n",
      "Preprune count: 59693\n",
      "Postprune count: 59007\n",
      "Pruned 686 links or 1.15%\n",
      "Preprune count: 59939\n",
      "Postprune count: 59253\n",
      "Pruned 686 links or 1.14%\n",
      "Preprune count: 60178\n",
      "Postprune count: 59492\n",
      "Pruned 686 links or 1.14%\n",
      "Preprune count: 60434\n",
      "Postprune count: 59748\n",
      "Pruned 686 links or 1.14%\n",
      "Preprune count: 60689\n",
      "Postprune count: 60003\n",
      "Pruned 686 links or 1.13%\n",
      "Preprune count: 60945\n",
      "Postprune count: 60259\n",
      "Pruned 686 links or 1.13%\n",
      "Preprune count: 61167\n",
      "Postprune count: 60481\n",
      "Pruned 686 links or 1.12%\n",
      "Preprune count: 61417\n",
      "Postprune count: 60731\n",
      "Pruned 686 links or 1.12%\n",
      "Preprune count: 61649\n",
      "Postprune count: 60963\n",
      "Pruned 686 links or 1.11%\n",
      "Preprune count: 61868\n",
      "Postprune count: 61182\n",
      "Pruned 686 links or 1.11%\n",
      "Preprune count: 62077\n",
      "Postprune count: 61391\n",
      "Pruned 686 links or 1.11%\n",
      "Preprune count: 62293\n",
      "Postprune count: 61607\n",
      "Pruned 686 links or 1.10%\n",
      "Preprune count: 62541\n",
      "Postprune count: 61855\n",
      "Pruned 686 links or 1.10%\n",
      "Preprune count: 62795\n",
      "Postprune count: 62109\n",
      "Pruned 686 links or 1.09%\n",
      "Preprune count: 63053\n",
      "Postprune count: 62367\n",
      "Pruned 686 links or 1.09%\n",
      "Preprune count: 63298\n",
      "Postprune count: 62612\n",
      "Pruned 686 links or 1.08%\n",
      "Preprune count: 63513\n",
      "Postprune count: 62827\n",
      "Pruned 686 links or 1.08%\n",
      "Preprune count: 63775\n",
      "Postprune count: 63089\n",
      "Pruned 686 links or 1.08%\n",
      "Preprune count: 64013\n",
      "Postprune count: 63327\n",
      "Pruned 686 links or 1.07%\n",
      "Preprune count: 64217\n",
      "Postprune count: 63531\n",
      "Pruned 686 links or 1.07%\n",
      "Preprune count: 64439\n",
      "Postprune count: 63753\n",
      "Pruned 686 links or 1.06%\n",
      "Preprune count: 64657\n",
      "Postprune count: 63971\n",
      "Pruned 686 links or 1.06%\n",
      "Preprune count: 64909\n",
      "Postprune count: 64223\n",
      "Pruned 686 links or 1.06%\n",
      "Preprune count: 65129\n",
      "Postprune count: 64443\n",
      "Pruned 686 links or 1.05%\n",
      "Preprune count: 65335\n",
      "Postprune count: 64649\n",
      "Pruned 686 links or 1.05%\n",
      "Preprune count: 65578\n",
      "Postprune count: 64892\n",
      "Pruned 686 links or 1.05%\n",
      "Preprune count: 65844\n",
      "Postprune count: 65158\n",
      "Pruned 686 links or 1.04%\n",
      "Preprune count: 66098\n",
      "Postprune count: 65412\n",
      "Pruned 686 links or 1.04%\n",
      "Preprune count: 66355\n",
      "Postprune count: 65669\n",
      "Pruned 686 links or 1.03%\n",
      "Preprune count: 66593\n",
      "Postprune count: 65907\n",
      "Pruned 686 links or 1.03%\n",
      "Preprune count: 66821\n",
      "Postprune count: 66135\n",
      "Pruned 686 links or 1.03%\n",
      "Preprune count: 67031\n",
      "Postprune count: 66345\n",
      "Pruned 686 links or 1.02%\n",
      "Preprune count: 67293\n",
      "Postprune count: 66607\n",
      "Pruned 686 links or 1.02%\n",
      "Preprune count: 67546\n",
      "Postprune count: 66860\n",
      "Pruned 686 links or 1.02%\n",
      "Preprune count: 67756\n",
      "Postprune count: 67070\n",
      "Pruned 686 links or 1.01%\n",
      "Preprune count: 67978\n",
      "Postprune count: 67292\n",
      "Pruned 686 links or 1.01%\n",
      "Preprune count: 68238\n",
      "Postprune count: 67552\n",
      "Pruned 686 links or 1.01%\n",
      "Preprune count: 68465\n",
      "Postprune count: 67779\n",
      "Pruned 686 links or 1.00%\n",
      "Preprune count: 68682\n",
      "Postprune count: 67996\n",
      "Pruned 686 links or 1.00%\n",
      "Preprune count: 68905\n",
      "Postprune count: 68219\n",
      "Pruned 686 links or 1.00%\n",
      "Preprune count: 69143\n",
      "Postprune count: 68457\n",
      "Pruned 686 links or 0.99%\n",
      "Preprune count: 69373\n",
      "Postprune count: 68687\n",
      "Pruned 686 links or 0.99%\n",
      "Preprune count: 69613\n",
      "Postprune count: 68927\n",
      "Pruned 686 links or 0.99%\n",
      "Preprune count: 69828\n",
      "Postprune count: 69142\n",
      "Pruned 686 links or 0.98%\n",
      "Preprune count: 70084\n",
      "Postprune count: 69398\n",
      "Pruned 686 links or 0.98%\n",
      "Preprune count: 70332\n",
      "Postprune count: 69646\n",
      "Pruned 686 links or 0.98%\n",
      "Preprune count: 70589\n",
      "Postprune count: 69903\n",
      "Pruned 686 links or 0.97%\n",
      "Preprune count: 70819\n",
      "Postprune count: 70133\n",
      "Pruned 686 links or 0.97%\n",
      "Preprune count: 71059\n",
      "Postprune count: 70373\n",
      "Pruned 686 links or 0.97%\n",
      "Preprune count: 71273\n",
      "Postprune count: 70587\n",
      "Pruned 686 links or 0.96%\n",
      "Preprune count: 71505\n",
      "Postprune count: 70819\n",
      "Pruned 686 links or 0.96%\n",
      "Preprune count: 71765\n",
      "Postprune count: 71079\n",
      "Pruned 686 links or 0.96%\n",
      "Preprune count: 71982\n",
      "Postprune count: 71296\n",
      "Pruned 686 links or 0.95%\n",
      "Preprune count: 72251\n",
      "Postprune count: 71565\n",
      "Pruned 686 links or 0.95%\n",
      "Preprune count: 72515\n",
      "Postprune count: 71829\n",
      "Pruned 686 links or 0.95%\n",
      "Preprune count: 72791\n",
      "Postprune count: 72105\n",
      "Pruned 686 links or 0.94%\n",
      "Preprune count: 73056\n",
      "Postprune count: 72370\n",
      "Pruned 686 links or 0.94%\n",
      "Preprune count: 73267\n",
      "Postprune count: 72581\n",
      "Pruned 686 links or 0.94%\n",
      "Preprune count: 73471\n",
      "Postprune count: 72785\n",
      "Pruned 686 links or 0.93%\n",
      "Preprune count: 73725\n",
      "Postprune count: 73039\n",
      "Pruned 686 links or 0.93%\n",
      "Preprune count: 73989\n",
      "Postprune count: 73303\n",
      "Pruned 686 links or 0.93%\n",
      "Preprune count: 74254\n",
      "Postprune count: 73568\n",
      "Pruned 686 links or 0.92%\n",
      "Preprune count: 74505\n",
      "Postprune count: 73819\n",
      "Pruned 686 links or 0.92%\n",
      "Preprune count: 74750\n",
      "Postprune count: 74064\n",
      "Pruned 686 links or 0.92%\n",
      "Preprune count: 74965\n",
      "Postprune count: 74279\n",
      "Pruned 686 links or 0.92%\n"
     ]
    }
   ],
   "source": [
    "clean_up_drudge_links()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the same thing for the FT. I should probably generalize this to a scraper class, but it's python baby, _we're all about the duct tape._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from waybackpy import WaybackMachineCDXServerAPI\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import re\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# mkdir 01-some-data/ft.com\n",
    "if not os.path.exists(\"01-some-data/ft.com\"):\n",
    "    os.mkdir(\"01-some-data/ft.com\")\n",
    "\n",
    "username = os.getenv('SMARTPROXY_USERNAME')\n",
    "password = os.getenv('SMARTPROXY_PASSWORD')\n",
    "proxy = f\"https://{username}:{password}@gate.smartproxy.com:7000\"\n",
    "\n",
    "proxies = {'https': proxy}\n",
    "user_agent = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36\"\n",
    "headers = {'User-Agent': user_agent}\n",
    "\n",
    "def get_ft_links_at_date(url, year, month, day, hour, minute):\n",
    "    w = WaybackMachineCDXServerAPI(url, user_agent=user_agent)\n",
    "    url = w.near(year=year, month=month, day=day, hour=hour, minute=minute).archive_url\n",
    "    response = requests.get(url, headers=headers, proxies=proxies)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    # TODO: find the right selector\n",
    "    links = soup.find_all('a')\n",
    "    article_links = [(link.get('href'), link.text) for link in links]\n",
    "    article_links = [link for link in article_links if link[1]]\n",
    "    return article_links\n",
    "\n",
    "def scrape_ft_with_proxy():\n",
    "    now = pd.Timestamp.now()\n",
    "    dates = pd.date_range(start=\"2022-01-01\", end=now, freq=\"D\")\n",
    "\n",
    "    for date in tqdm(dates, desc=\"FT progress\", unit=\"date\"):\n",
    "        # check if we already have the data\n",
    "        if os.path.exists(f\"01-some-data/ft.com/{date}.jsonl\"):\n",
    "            continue\n",
    "        data = []\n",
    "        am_links = get_ft_links_at_date(\"https://ft.com/\", year=date.year, month=date.month, day=date.day, hour=6, minute=0)\n",
    "        for url, text in am_links:\n",
    "            data.append({\"date\": date.isoformat(), \"url\": url, \"text\": text, \"isMorning\": True})\n",
    "        pm_links = get_ft_links_at_date(\"https://ft.com/\", year=date.year, month=date.month, day=date.day, hour=18, minute=0)\n",
    "        for url, text in pm_links:\n",
    "            data.append({\"date\": date.isoformat(), \"url\": url, \"text\": text, \"isMorning\": False})\n",
    "        # write to jsonl\n",
    "        with open(f\"01-some-data/ft.com/{date}.jsonl\", \"w\") as f:\n",
    "            for row in data:\n",
    "                f.write(json.dumps(row) + \"\\n\")\n",
    "        os.system('afplay /System/Library/Sounds/Pop.aiff')\n",
    "\n",
    "def clean_up_ft_links():\n",
    "    # iterate over each file in the directory\n",
    "    preprune_count = 0\n",
    "    postprune_count = 0\n",
    "    for filename in os.listdir(\"01-some-data/ft.com\"):\n",
    "        filepath = os.path.join(\"01-some-data/ft.com\", filename)\n",
    "        with open(filepath, 'r') as f:\n",
    "            data = [json.loads(line) for line in f]\n",
    "\n",
    "        # regex pattern to match everything after the last http, including the http\n",
    "\n",
    "        pattern = r\"(http[s]?://.*)\"\n",
    "\n",
    "        # iterate over each item in the data\n",
    "        for item in data:\n",
    "            # replace the matched pattern with an empty string\n",
    "            match = re.search(pattern, item['url'])\n",
    "            if match:\n",
    "                item['url'] = match.group(1)\n",
    "        # only include urls with /content/ in them\n",
    "        filtered = [item for item in data if \"/content/\" in item['url']]\n",
    "\n",
    "        preprune_count += len(data)\n",
    "        postprune_count += len(filtered)\n",
    "\n",
    "        # write the filtered data back to the file\n",
    "        with open(filepath, 'w') as f:\n",
    "            for item in filtered:\n",
    "                f.write(json.dumps(item) + \"\\n\")\n",
    "\n",
    "        print(f\"Preprune count: {preprune_count}\")\n",
    "        print(f\"Postprune count: {postprune_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from retrying import retry\n",
    "\n",
    "@retry(wait_exponential_multiplier=1000, wait_exponential_max=60000)\n",
    "def scrape_ft_with_proxy_retry():\n",
    "    scrape_ft_with_proxy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprune count: 261\n",
      "Postprune count: 261\n",
      "Preprune count: 525\n",
      "Postprune count: 525\n",
      "Preprune count: 804\n",
      "Postprune count: 804\n",
      "Preprune count: 1072\n",
      "Postprune count: 1072\n",
      "Preprune count: 1342\n",
      "Postprune count: 1342\n",
      "Preprune count: 1612\n",
      "Postprune count: 1612\n",
      "Preprune count: 1871\n",
      "Postprune count: 1871\n",
      "Preprune count: 2135\n",
      "Postprune count: 2135\n",
      "Preprune count: 2394\n",
      "Postprune count: 2394\n",
      "Preprune count: 2653\n",
      "Postprune count: 2653\n",
      "Preprune count: 2916\n",
      "Postprune count: 2916\n",
      "Preprune count: 3177\n",
      "Postprune count: 3177\n",
      "Preprune count: 3438\n",
      "Postprune count: 3438\n",
      "Preprune count: 3719\n",
      "Postprune count: 3719\n",
      "Preprune count: 3987\n",
      "Postprune count: 3987\n",
      "Preprune count: 4253\n",
      "Postprune count: 4253\n",
      "Preprune count: 4518\n",
      "Postprune count: 4518\n",
      "Preprune count: 4782\n",
      "Postprune count: 4782\n",
      "Preprune count: 5053\n",
      "Postprune count: 5053\n",
      "Preprune count: 5320\n",
      "Postprune count: 5320\n",
      "Preprune count: 5596\n",
      "Postprune count: 5596\n",
      "Preprune count: 5880\n",
      "Postprune count: 5880\n",
      "Preprune count: 6147\n",
      "Postprune count: 6147\n",
      "Preprune count: 6424\n",
      "Postprune count: 6424\n",
      "Preprune count: 6686\n",
      "Postprune count: 6686\n",
      "Preprune count: 6956\n",
      "Postprune count: 6956\n",
      "Preprune count: 7218\n",
      "Postprune count: 7218\n"
     ]
    }
   ],
   "source": [
    "clean_up_ft_links()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from waybackpy import WaybackMachineCDXServerAPI\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import re\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# mkdir 01-some-data/bloomberg.com\n",
    "if not os.path.exists(\"01-some-data/bloomberg.com\"):\n",
    "  os.mkdir(\"01-some-data/bloomberg.com\")\n",
    "\n",
    "username = os.getenv('SMARTPROXY_USERNAME')\n",
    "password = os.getenv('SMARTPROXY_PASSWORD')\n",
    "proxy = f\"https://{username}:{password}@gate.smartproxy.com:7000\"\n",
    "\n",
    "proxies = {'https': proxy}\n",
    "user_agent = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36\"\n",
    "headers = {'User-Agent': user_agent}\n",
    "\n",
    "def get_bloomberg_links_at_date(url, year, month, day, hour, minute):\n",
    "  w = WaybackMachineCDXServerAPI(url, user_agent=user_agent)\n",
    "  url = w.near(year=year, month=month, day=day, hour=hour, minute=minute).archive_url\n",
    "  response = requests.get(url, headers=headers, proxies=proxies)\n",
    "  soup = BeautifulSoup(response.text, 'html.parser')\n",
    "  # TODO: find the right selector\n",
    "  links = soup.find_all('a')\n",
    "  article_links = [(link.get('href'), link.text) for link in links]\n",
    "  article_links = [link for link in article_links if link[1]]\n",
    "  return article_links\n",
    "\n",
    "def scrape_bloomberg_with_proxy():\n",
    "  now = pd.Timestamp.now()\n",
    "  dates = pd.date_range(start=\"2022-01-01\", end=now, freq=\"D\")\n",
    "\n",
    "  for date in tqdm(dates, desc=\"Bloomberg progress\", unit=\"date\"):\n",
    "    # check if we already have the data\n",
    "    if os.path.exists(f\"01-some-data/bloomberg.com/{date}.jsonl\"):\n",
    "      continue\n",
    "    data = []\n",
    "    am_links = get_bloomberg_links_at_date(\"https://www.bloomberg.com/markets\", year=date.year, month=date.month, day=date.day, hour=6, minute=0)\n",
    "    for url, text in am_links:\n",
    "      data.append({\"date\": date.isoformat(), \"url\": url, \"text\": text, \"isMorning\": True})\n",
    "    pm_links = get_bloomberg_links_at_date(\"https://www.bloomberg.com/markets\", year=date.year, month=date.month, day=date.day, hour=18, minute=0)\n",
    "    for url, text in pm_links:\n",
    "      data.append({\"date\": date.isoformat(), \"url\": url, \"text\": text, \"isMorning\": False})\n",
    "    # write to jsonl\n",
    "    with open(f\"01-some-data/bloomberg.com/{date}.jsonl\", \"w\") as f:\n",
    "      for row in data:\n",
    "        f.write(json.dumps(row) + \"\\n\")\n",
    "    os.system('afplay /System/Library/Sounds/Pop.aiff')\n",
    "\n",
    "def clean_up_bloomberg_links():\n",
    "  # iterate over each file in the directory\n",
    "  preprune_count = 0\n",
    "  postprune_count = 0\n",
    "  for filename in os.listdir(\"01-some-data/bloomberg.com\"):\n",
    "    filepath = os.path.join(\"01-some-data/bloomberg.com\", filename)\n",
    "    with open(filepath, 'r') as f:\n",
    "      data = [json.loads(line) for line in f]\n",
    "\n",
    "    # regex pattern to match everything after the last http, including the http\n",
    "\n",
    "    pattern = r\"(http[s]?://.*)\"\n",
    "\n",
    "    # iterate over each item in the data\n",
    "    for item in data:\n",
    "      # replace the matched pattern with an empty string\n",
    "      match = re.search(pattern, item['url'])\n",
    "      if match:\n",
    "        item['url'] = match.group(1)\n",
    "\n",
    "      # trim the text\n",
    "      item['text'] = item['text'].strip()\n",
    "    # only include urls with /news/articles/ in them\n",
    "    filtered = [item for item in data if \"/news/articles/\" in item['url']]\n",
    "    # remove those with text len less than 5\n",
    "    filtered = [item for item in filtered if len(item['text']) > 5]\n",
    "\n",
    "\n",
    "    preprune_count += len(data)\n",
    "    postprune_count += len(filtered)\n",
    "\n",
    "    # write the filtered data back to the file\n",
    "    with open(filepath, 'w') as f:\n",
    "      for item in filtered:\n",
    "        f.write(json.dumps(item) + \"\\n\")\n",
    "\n",
    "    print(f\"Preprune count: {preprune_count}\")\n",
    "    print(f\"Postprune count: {postprune_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from retrying import retry\n",
    "\n",
    "@retry(wait_exponential_multiplier=1000, wait_exponential_max=60000)\n",
    "def scrape_bloomberg_with_proxy_retry():\n",
    "  scrape_bloomberg_with_proxy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprune count: 42\n",
      "Postprune count: 42\n",
      "Preprune count: 84\n",
      "Postprune count: 84\n",
      "Preprune count: 124\n",
      "Postprune count: 124\n",
      "Preprune count: 145\n",
      "Postprune count: 145\n"
     ]
    }
   ],
   "source": [
    "clean_up_bloomberg_links()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They all do their thing, now I'll let this puppy run over _night and see what we get._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping progress:  29%|       | 226/789 [03:17<08:10,  1.15date/s]\n",
      "Scraping progress:  32%|      | 254/789 [08:01<2:47:46, 18.82s/date]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from retrying import retry\n",
    "\n",
    "@retry(wait_exponential_multiplier=1000, wait_exponential_max=60000)\n",
    "def run_all_scrapers():\n",
    "  # Scrape drudgereport.com\n",
    "  try:\n",
    "    scrape_drudge_with_proxy_retry()\n",
    "  except Exception as e:\n",
    "    print(\"An error occurred while scraping drudgereport.com:\", str(e))\n",
    "\n",
    "  # Scrape ft.com\n",
    "  try:\n",
    "    scrape_ft_with_proxy_retry()\n",
    "  except Exception as e:\n",
    "    print(\"An error occurred while scraping ft.com:\", str(e))\n",
    "\n",
    "  # Scrape bloomberg.com\n",
    "  try:\n",
    "    scrape_bloomberg_with_proxy_retry()\n",
    "  except Exception as e:\n",
    "    print(\"An error occurred while scraping bloomberg.com:\", str(e))\n",
    "\n",
    "try:\n",
    "  run_all_scrapers()\n",
    "  os.system('say \"All scrapers have finished running.\"')\n",
    "except Exception as e:\n",
    "  print(\"An error occurred while running all scrapers:\", str(e))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
